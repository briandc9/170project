{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "sys.path.append('../..')\n",
    "import argparse\n",
    "import utils\n",
    "\n",
    "from student_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import student_utils as s_utils\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  Complete the following function.\n",
    "======================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "======================================================================\n",
    "  Complete the following function.\n",
    "======================================================================\n",
    "\"\"\"\n",
    "\n",
    "def solve(list_of_locations, list_of_homes, starting_car_location, adjacency_matrix, params=[]):\n",
    "    \"\"\"\n",
    "    Write your algorithm here.\n",
    "    Input:\n",
    "        list_of_locations: A list of locations such that node i of the graph corresponds to name at index i of the list\n",
    "        list_of_homes: A list of homes\n",
    "        starting_car_location: The name of the starting location for the car\n",
    "        adjacency_matrix: The adjacency matrix from the input file\n",
    "    Output:\n",
    "        A list of locations representing the car path\n",
    "        A dictionary mapping drop-off location to a list of homes of TAs that got off at that particular location\n",
    "        NOTE: both outputs should be in terms of indices not the names of the locations themselves\n",
    "    \"\"\"\n",
    "    # Make networkx graph G\n",
    "    #G = make_graph(adjacency_matrix)\n",
    "    G = s_utils.adjacency_matrix_to_graph(adjacency_matrix)\n",
    "    \n",
    "    #Get adjacency dictionary of distances for each location\n",
    "    adjacencies = make_dictionary(adjacency_matrix, list_of_locations)\n",
    "    \n",
    "    # Get indices of homes\n",
    "    home_indices = [list_of_locations.index(i) for i in list_of_homes]\n",
    "    \n",
    "    #Get nodes\n",
    "    nodes = make_nodes(adjacencies, list_of_homes, home_indices)\n",
    "    node_homes = list(nodes.keys())\n",
    "    \n",
    "    node_paths, node_G = shortest_paths(G, list_of_locations, node_homes)\n",
    "    \n",
    "    #TSP on node_G\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert adjacency matrix -> pd DataFrame -> networkx Graph\n",
    "def make_graph(adjacency_matrix):\n",
    "    adj = adjacency_matrix\n",
    "    \n",
    "    df = pd.DataFrame(adj)\n",
    "    df = df.replace(\"x\", 0)\n",
    "        \n",
    "    G = nx.from_pandas_adjacency(df)\n",
    "    G.name = 'Graph from pandas adjacency matrix'\n",
    "    \n",
    "    print(nx.info(G))\n",
    "    \n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns adjacency dictionary of distances for each location {location: [distances to every location], ...}\n",
    "\n",
    "def make_dictionary(adjacency_matrix, locations):\n",
    "    #Create dictionary for every location\n",
    "    adjacencies = {}\n",
    "    \n",
    "    #Create dictionary of adjacencent locations for every location\n",
    "    # adjacencies = {\"loc\" : [distance to every other loc], ...}\n",
    "    # If distance == \"x\" -> None\n",
    "    for i in range(0,len(locations)):\n",
    "        adj = [None if j == \"x\" else j for j in adjacency_matrix[i]]\n",
    "        adjacencies[locations[i]] = adj\n",
    "    \n",
    "    return adjacencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"TODO: Change nodes to locations instead of just homes\"\"\" \n",
    "# Returns dictionary of {node_home: [homes belonging to node], ...}\n",
    "\n",
    "def make_nodes(adjacencies, homes, home_indices):    \n",
    "    limit = 12000 #maximum distance away from node's base\n",
    "    nodes = {} #create a node around every location\n",
    "    \n",
    "    #Create nodes for every home\n",
    "    for home in homes:\n",
    "        nodes[home] = [home] #Start every home's node with itself\n",
    "        \n",
    "        for index in home_indices:\n",
    "            distance = adjacencies[home][index]\n",
    "            if (distance != None) and (distance < limit):\n",
    "                #append other home that is within limit to the node starting at that home\n",
    "                current = nodes[home]\n",
    "                nodes[home].append(homes[index]) #returns None\n",
    "    \n",
    "    #print(nodes)\n",
    "    \n",
    "    \n",
    "    #Clean up node dictionary to only contain largest nodes ------------\n",
    "    deleted_nodes = nodes.copy()\n",
    "    homes_represented = homes\n",
    "    nodes_to_keep = list()\n",
    "    \n",
    "    #for node in node.keys():\n",
    "    \n",
    "    while homes_represented:         \n",
    "        v = list(deleted_nodes.values())\n",
    "        k = list(deleted_nodes.keys())\n",
    "        biggest_node = k[v.index(max(v, key=len))]\n",
    "        \n",
    "        #remove homes that are already included in list\n",
    "        homes_represented = [x for x in homes_represented if x not in nodes[biggest_node]]\n",
    "        \n",
    "        for home in nodes[biggest_node]:\n",
    "            deleted_nodes.pop(home, None)\n",
    "        \n",
    "        nodes_to_keep.append(biggest_node)\n",
    "    \n",
    "    #print(nodes_to_keep)\n",
    "    \n",
    "    return {key: nodes[key] for key in nodes_to_keep}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns dictionary of shortest paths between nodes {(node_1, node_2): [list of path], ...} \n",
    "#    for outputting driver path\n",
    "#returns new graph of just nodes and their associated distances\n",
    "#    for TSP solving with dwave\n",
    "\n",
    "def shortest_paths(G, list_of_locations, node_homes):\n",
    "    node_paths = {}\n",
    "    #node_distances = {}\n",
    "    \n",
    "    #Make new graph of nodes\n",
    "    node_G = nx.Graph()\n",
    "    \n",
    "    for node in node_homes:\n",
    "        node_G.add_node(node)\n",
    "    \n",
    "    #Get shortest path between every node and the distance of that path\n",
    "    for node_s in node_homes:\n",
    "        node_paths[node_s] = list()\n",
    "        for node_t in node_homes:\n",
    "            index_s = list_of_locations.index(node_s)\n",
    "            index_t = list_of_locations.index(node_t)\n",
    "            path = nx.shortest_path(G, source = index_s, target = index_t, weight = \"weight\")\n",
    "            node_paths[(node_s, node_t)] = path\n",
    "            \n",
    "            path_weight = nx.shortest_path_length(G, source= index_s, target= index_t, weight= \"weight\")[\n",
    "            node_G.add_edge(node_s, node_t, weight= path_weight)\n",
    "    \n",
    "    print(node_G.edges())\n",
    "    \n",
    "    return node_paths, node_G\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use dwave tsp.python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "======================================================================\n",
    "   No need to change any code below this line\n",
    "======================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "======================================================================\n",
    "   No need to change any code below this line\n",
    "======================================================================\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Convert solution with path and dropoff_mapping in terms of indices\n",
    "and write solution output in terms of names to path_to_file + file_number + '.out'\n",
    "\n",
    "! dropoff_mapping = dicitonary of {dropoff_loc, [list of TAs dropped off]}\n",
    "\"\"\"\n",
    "def convertToFile(path, dropoff_mapping, path_to_file, list_locs):\n",
    "    string = ''\n",
    "    for node in path:\n",
    "        string += list_locs[node] + ' '\n",
    "    string = string.strip()\n",
    "    string += '\\n'\n",
    "\n",
    "    dropoffNumber = len(dropoff_mapping.keys())\n",
    "    string += str(dropoffNumber) + '\\n'\n",
    "    for dropoff in dropoff_mapping.keys():\n",
    "        strDrop = list_locs[dropoff] + ' '\n",
    "        for node in dropoff_mapping[dropoff]:\n",
    "            strDrop += list_locs[node] + ' '\n",
    "        strDrop = strDrop.strip()\n",
    "        strDrop += '\\n'\n",
    "        string += strDrop\n",
    "    utils.write_to_file(path_to_file, string)\n",
    "\n",
    "def solve_from_file(input_file, output_directory, params=[]):\n",
    "    print('Processing', input_file)\n",
    "\n",
    "    input_data = utils.read_file(input_file)\n",
    "    num_of_locations, num_houses, list_locations, list_houses, starting_car_location, adjacency_matrix = data_parser(input_data)\n",
    "    car_path, drop_offs = solve(list_locations, list_houses, starting_car_location, adjacency_matrix, params=params)\n",
    "\n",
    "    basename, filename = os.path.split(input_file)\n",
    "    if not os.path.exists(output_directory):\n",
    "        os.makedirs(output_directory)\n",
    "    output_file = utils.input_to_output(input_file, output_directory)\n",
    "\n",
    "    convertToFile(car_path, drop_offs, output_file, list_locations)\n",
    "\n",
    "\n",
    "def solve_all(input_directory, output_directory, params=[]):\n",
    "    input_files = utils.get_files_with_extension(input_directory, 'in')\n",
    "\n",
    "    for input_file in input_files:\n",
    "        solve_from_file(input_file, output_directory, params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--all] input [output_directory] ...\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    parser = argparse.ArgumentParser(description='Parsing arguments')\n",
    "    parser.add_argument('--all', action='store_true', help='If specified, the solver is run on all files in the input directory. Else, it is run on just the given input file')\n",
    "    parser.add_argument('input', type=str, help='The path to the input file or directory')\n",
    "    parser.add_argument('output_directory', type=str, nargs='?', default='.', help='The path to the directory where the output should be written')\n",
    "    parser.add_argument('params', nargs=argparse.REMAINDER, help='Extra arguments passed in')\n",
    "    args = parser.parse_args()\n",
    "    output_directory = args.output_directory\n",
    "    if args.all:\n",
    "        input_directory = args.input\n",
    "        solve_all(input_directory, output_directory, params=args.params)\n",
    "    else:\n",
    "        input_file = args.input\n",
    "        solve_from_file(input_file, output_directory, params=args.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing inputs/100_50.in\n",
      "['Oakmere', 'Valhaven', 'Freyview', 'Newby', 'Ironshore', 'Butterbush', 'Morwald']\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-72-bd1d03742d8b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msolve_from_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"inputs/100_50.in\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"outputs_imam\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-9-d9897a05e366>\u001b[0m in \u001b[0;36msolve_from_file\u001b[1;34m(input_file, output_directory, params)\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[0minput_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[0mnum_of_locations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_houses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist_locations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist_houses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstarting_car_location\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madjacency_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_parser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m     \u001b[0mcar_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdrop_offs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msolve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist_locations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist_houses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstarting_car_location\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madjacency_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[0mbasename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "source": [
    "solve_from_file(\"inputs/100_50.in\", \"outputs_imam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
